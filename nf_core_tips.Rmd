---
title: "nf-core tips"
author: "Austyn Trull and Lara Ianov, Ph.D."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# General Notes
* Use at minimum 3 samples when running a pipeline (even for minimal testing purposes). Some pipelines will not be able to complete successfully when running only a single sample.
* Although not a requirement, we advise to not use the iGenomes option suggested in a number of pipelines due to the lack of information on versioning linked to each assembly which may compromise reproducibility to a small degree. Instead pass on a reference (genome, and annotation file(s)) from a source and version that is suitable to your needs.
* Some tips that we have found require the use of a custom config. Custom configs allow for modifying the values the pipeline uses, including passing in new command flags to the underlying software the pipeline uses. Custom configs are passed in via the command line using `-c ${custom_config}`, where `-c` is the command flag and `${custom_config}` is the path to the custom config.
  * Importantly, a custom config should only reflect arguments or modifications linked to the process if not available through the pipeline parameters. This is linked to an issue in Nextflow which is being tracked at https://github.com/nextflow-io/nextflow/issues/2662. Thus, standard pipeline parameters should be provided through the command line during the execution of the pipeline or in a yaml file with the usage of the `-params-file` option (e.g.: `-params-file params.yml` where the yaml file contains all custom parameters). Discussion linked to a `params.yml` file can be found at https://github.com/nf-core/viralrecon/issues/283 and https://github.com/nf-core/rnaseq/issues/754.

# Executor mode for Cheaha profile

* U-BDS has created a public Cheaha profile which has been merged to the main nf-core configs (https://github.com/nf-core/configs/pull/322). Thus, the profile can be used in any nf-core pipeline with the parameter `-profile cheaha`. Full documentation of the profile can be found in the nf-core config GitHub: https://github.com/nf-core/configs/blob/master/docs/cheaha.md

We recommend to use this profile when processing multiple samples in the pipeline as it will aid in parallel processing. If your run only contains a small amount of samples, standard `local` mode (to a compute node) is usually sufficient. Feel free to let us know if additional customization would benefit the community.

# Pipeline-specific Notes
## nf-core/rnaseq

Although a user choice, we generally recommend to enable Salmon's flags `--seqBias --gcBias`. In version 3.6, enabling them can be done via a `custom.config`, by including the following (enabling the flags in the salmon run with star inputs, and with the salmon run where quasi-mapping was performed by salmon):

```
// tool params not linked to direct pipeline params. 
process {
    withName: '.*:QUANTIFY_STAR_SALMON:SALMON_QUANT' {
        ext.args = "--seqBias --gcBias"
    }

    withName: '.*:QUANTIFY_SALMON:SALMON_QUANT' {
        ext.args = "--seqBias --gcBias"
    }
}
```

Note that the syntax linked to custom parameters may differ from pipeline to pipeline or even versions. We recommend to following similar syntax to what is present in the `modules.config` of the pipeline of interest such as [this one for v.3.6](https://github.com/nf-core/rnaseq/blob/3.6/conf/modules.config). If you have questions about this, please feel free to ask a question linked to it during our data science office hours.

### Tips linked to reference
* The `transcript_fasta` is not a required parameter by the pipeline. If this is not provided by the user, it will be generated by the process called `RSEM_PREPAREREFERENCE_TRANSCRIPTS` (which may be renamed in the near-future as this process is executed whenever the user does not provide a transcriptome, regardless of the choice of `--aligner`). For more information, reference [here](https://nfcore.slack.com/archives/CE8SSJV3N/p1641824929069500)
* __If the user provides a file to__ `transcript_fasta` which is used at the Salmon steps, it should be a transcriptome file generated from `gffread` as opposed to one downloaded from GENCODE or Ensembl. Issues linked to Ensembl transcriptomes are derieved from the fact that the transcriptome files (even after coding and non-coding RNA concatenation) have less transcripts than the GTF file. The issues linked to GENCODE files are linked to an issue in the pipeline which prevents it from correctly processing the off-the-shelf transcript fasta due to the sequence name format (despite enabling the `--gencode` parameter). For more information, reference [here](https://nfcore.slack.com/archives/CE8SSJV3N/p1642697218225700) and [here](https://nfcore.slack.com/archives/CE8SSJV3N/p1642699049230500)
    * It should be noted the current recommended way to use reference files generally is to provide the `--fasta` and `--gtf` along with `--save_reference` the first time you run the pipeline and then let it generate all of the downstream artifacts like the transcriptome and indices to be recycled thereafter via including them in them as params in the yml. This is the way recommended by the authors per the nf-core/rnaseq slack channel. For more information, reference [here](https://nfcore.slack.com/archives/CE8SSJV3N/p1642698848229000)

`gffread` example:

```
samtools faidx Mus_musculus.GRCm38.dna.primary_assembly.fa

gffread -w Mus_musculus.GRCm38_GTF_matched_transcripts.fa -g ./Mus_musculus.GRCm38.dna.primary_assembly.fa Mus_musculus.GRCm38.102.gtf
```

From the example above, the newly generated transcriptome `Mus_musculus.GRCm38_GTF_matched_transcripts.fa` would be passed on to the pipeline.

We recommend to creata a conda environment with both dependencies and record the versions.

`gffread` documentation can be found from: http://ccb.jhu.edu/software/stringtie/gff.shtml#gffread

* An issue has been opened with the nf-core team to add a warning regarding the points above linked to `transcript_fasta`: https://github.com/nf-core/rnaseq/issues/753

## nf-core/nanoseq
* The version of nanoplot that is used by this pipeline (1.38) causes the pipeline to crash. Per the author, the issue is with a package that is used to convert html files into png files. However, nanoseq expects there to be png files which causes crash. In order to get around this issue, you can create a custom config and override the container that nanoseq would pull down for Nanoplot. Values specified in configs passed via the commandline take priority over the defaults that are specified in the pipeline proper.
    * This problem is currently being tracked here: https://github.com/nf-core/nanoseq/issues/141

container override example:
```
process {
    withName: NANOPLOT {
        container = 'https://depot.galaxyproject.org/singularity/nanoplot:1.32.1--py_0'
    }
}
```
Place the above lines in a file called `custom.config`. When the pipleine is run, specify a new command-line parameter `-c path/to/custom.config` to the nextflow command, where `path/to/custom.config` would be the path to the custom config file.

## nf-core/fetchngs
* The input file passed in via the `--input` must end in `.txt`
* It is possible that curl may exceed the default timeout that is set in the pipeline. In order to increase or turn this off you will need a to add the below code to a custom config.
In order to turn off curl timelimit, the custom config will need to contain the following lines:
```
process {
    withName: SRA_FASTQ_FTP {
        ext.args = '--retry 5  --continue-at -'
    }
}
```

* If curl does not work, you can set the pipeline to use sra-toolkit instead. In order to set the pipeline to use sra-toolkit to download data, you will need to place the following lines into a `params.yml` file, and pass that to the pipeline by adding `-params-file params.yml` to the nextflow run command.
``` 
enable_conda: true
force_sra_downloads: true
```

* Prefetch has a default filesize (20GB), however files you download may be larger than this default. In order to increase the limit, you will want to place the following lines into a `custom.conf` file and pass it to the pipeline by adding `-c custom.conf` to the nextflow run command. Note that this command sets the max size to 50GB but just tweak this number to accommodate your downloads
```
process {
    withName: SRATOOLS_PREFETCH {
        ext.args = '--max-size 50G'
    }
}
```
